{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "#####################\n",
    "# Load Data\n",
    "#####################\n",
    "\n",
    "# load data set_v1\n",
    "excel_file = 'image-manipulation (timeseries)/Caldwell_ImageManipulation-EyeGaze_DataSetCombined.xlsx'\n",
    "olddata = pd.read_excel(excel_file, sheet_name=1)\n",
    "# rename the labels of dataset_v1\n",
    "olddata.rename(columns={'participant':'Participant_ID'}, inplace=True)\n",
    "olddata.rename(columns={'image':'Image_ID'}, inplace=True)\n",
    "# load data set_2\n",
    "excel_file = 'image-manipulation_v2/Caldwell_Manip_Images_10-14_TimeSeries.csv'\n",
    "predata = pd.read_csv(excel_file)\n",
    "# merge two dataset by the 'Participant_ID','Image_ID'\n",
    "predata2 = pd.merge(predata,olddata,how='left', on=['Participant_ID','Image_ID'])\n",
    "# remove the useless column from dataset_v1\n",
    "newdata = predata2.iloc[:, [0,1,2,3,4,5,6,7,8,13,14]]\n",
    "# sort the dataset by start time\n",
    "data = newdata.sort_values(by=['Start Time'])\n",
    "\n",
    "# normalization the dataset between 0 and 1 by Min-Max scaling\n",
    "# https://sebastianraschka.com/Articles/2014_about_feature_scaling.html#about-min-max-scaling\n",
    "for i in range(0, data.shape[1] - 2):\n",
    "    dataMax = data[[data.columns[i]]].max()\n",
    "    dataMin = data[[data.columns[i]]].min()\n",
    "    data[[data.columns[i]]] = (data[[data.columns[i]]] - dataMin)/ (dataMax - dataMin)\n",
    "\n",
    "# use the Image_ID 10-12 (after normalization 0-0.5)as the train data,13 (0.75) as validate data and 14 (1.0) as test data\n",
    "traindata = data.loc[data['Image_ID'] < 0.75]\n",
    "\n",
    "validatedata = data.loc[data['Image_ID'] == 0.75]\n",
    "\n",
    "testdata = data.loc[data['Image_ID'] == 1.0]\n",
    "\n",
    "train_input = traindata.iloc[:, :9]\n",
    "train_target = traindata.iloc[:, -1]\n",
    "\n",
    "validate_input = validatedata.iloc[:, :9]\n",
    "validate_target = validatedata.iloc[:, -1]\n",
    "\n",
    "test_input = testdata.iloc[:, :9]\n",
    "test_target = testdata.iloc[:, -1]\n",
    "\n",
    "X_train = Variable(torch.Tensor(train_input.values).float())\n",
    "Y_train = Variable(torch.Tensor(train_target.values).long())\n",
    "\n",
    "X_validate = Variable(torch.Tensor(validate_input.values).float())\n",
    "Y_validate = Variable(torch.Tensor(validate_target.values).long())\n",
    "\n",
    "X_test = Variable(torch.Tensor(test_input.values).float())\n",
    "Y_test = Variable(torch.Tensor(test_target.values).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(9, 10, batch_first=True)\n",
       "  (fc): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# LSTM model\n",
    "#####################\n",
    "\n",
    "n_features = 9\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "batch_size = 1\n",
    "#num_hidden_layer = 1\n",
    "input_dim = n_features\n",
    "hidden_dim = 10\n",
    "output_dim=3\n",
    "num_layers=1\n",
    "\n",
    "# reference example LSTM\n",
    "# https://www.jessicayung.com/lstms-for-time-series-in-pytorch/\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim, num_layers, batch_first=True):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        #input = input.unsqueeze(0)\n",
    "\n",
    "        # Initialize hidden state with zeros\n",
    "        #h0 = torch.zeros(self.num_layers, input.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        #c0 = torch.zeros(self.num_layers, input.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        \n",
    "        out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        #out, self.hidden = self.lstm(input)\n",
    "        #out, (hn, cn) = self.lstm(input, (h0.detach(), c0.detach()))\n",
    "\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        #out = self.fc(out[-1].view(self.batch_size, -1))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        out = F.softmax(out, dim = 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, batch_size, output_dim, num_layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at c:\\a\\w\\1\\s\\windows\\pytorch\\aten\\src\\thnn\\generic/ClassNLLCriterion.c:93",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-92826bab9019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mall_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 904\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1970\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   1789\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at c:\\a\\w\\1\\s\\windows\\pytorch\\aten\\src\\thnn\\generic/ClassNLLCriterion.c:93"
     ]
    }
   ],
   "source": [
    "# store all losses for visualisation\n",
    "all_losses = []\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "v_losses = []\n",
    "\"\"\"\n",
    "Train the neural network\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# train a neural network\n",
    "for epoch in range(num_epochs):\n",
    "    # Initialise hidden state\n",
    "    model.hidden = model.init_hidden()\n",
    "\n",
    "    # Perform forward pass: compute predicted y by passing x to the model.\n",
    "    Y_pred = model(X_train)\n",
    "    \n",
    "    Y_pred_validate = model(X_validate)\n",
    "    \n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    #loss_func = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_func(Y_pred, Y_train)\n",
    "    all_losses.append(loss.item())\n",
    "    \n",
    "        \n",
    "    lossv = loss_func(Y_pred_validate,Y_validate)\n",
    "    v_losses.append(lossv.item())\n",
    "\n",
    "\n",
    "    # Clear the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Perform backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimiser makes an update to its\n",
    "    # parameters\n",
    "    optimiser.step()\n",
    "    \n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        # convert three-column predicted Y values to one column for comparison\n",
    "        _, predicted = torch.max(Y_pred, 1)\n",
    "\n",
    "        # calculate and print accuracy\n",
    "        total = predicted.size(0)\n",
    "        correct = predicted.data.numpy() == Y_train.data.numpy()\n",
    "\n",
    "        #print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%'\n",
    "        #      % (epoch + 1, num_epochs, loss.item(), 100 * sum(correct)/total))\n",
    "        \n",
    "        print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%'\n",
    "              % (epoch + 1, num_epochs, loss.item(), 100 * sum(correct)/total))\n",
    "        \n",
    "        \n",
    "        # validate set\n",
    "        _, predictedv = torch.max(Y_pred_validate, 1)\n",
    "                \n",
    "        totalv = predictedv.size(0)\n",
    "        correctv = predictedv.data.numpy() == Y_validate.data.numpy()\n",
    "        \n",
    "        print('Validation Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%'\n",
    "              % (epoch + 1, num_epochs, lossv.item(), 100 * sum(correctv)/totalv))\n",
    "        \n",
    "\"\"\"\n",
    "Test the neural network\n",
    "\n",
    "Pass testing data to the built neural network and get its performance\n",
    "\"\"\"\n",
    "# test the neural network using testing data\n",
    "# It is actually performing a forward pass computation of predicted y\n",
    "# by passing x to the model.\n",
    "# Here, Y_pred_test contains three columns, where the index of the\n",
    "# max column indicates the class of the instance\n",
    "Y_pred_test = model(X_test)\n",
    "# get prediction\n",
    "# convert three-column predicted Y values to one column for comparison\n",
    "_, predicted_test = torch.max(Y_pred_test, 1)\n",
    "\n",
    "# calculate accuracy\n",
    "total_test = predicted_test.size(0)\n",
    "correct_test = sum(predicted_test.data.numpy() == Y_test.data.numpy())\n",
    "print('Testing Accuracy: %.2f %%' % (100 * correct_test / total_test))\n",
    "\n",
    "#print loss fig\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss (CrossEntropyLoss)\")\n",
    "\n",
    "plt.plot(all_losses,label=\"Train_losses\")\n",
    "plt.plot(v_losses, label=\"Validate_losses\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

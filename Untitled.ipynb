{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file implements a hybrid of genetic algorithm with LSTM for the image manipulation-eye gaze timeseries data set.\n",
    "It is designed to solve the classification problem about predicting the user's vote on if a picture is manipulated based\n",
    "on a sequence of data on their eye gaze.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19002, 9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 1: load data\n",
    "\"\"\"\n",
    "# load all data\n",
    "data = pd.read_excel('Caldwell_ImageManipulation-EyeGaze_DataSetCombined.xlsx',\n",
    "                        sheet_name='data')\n",
    "\n",
    "data = data[[\"participant\", \"image\", \"image manipulated\", \"vote\"]]\n",
    "\n",
    "data_extended = pd.read_csv('Caldwell_Manip_Images_10-14_TimeSeries.csv')\n",
    "# rename columns to make them align\n",
    "data_extended = data_extended.rename(index=str, columns={'Participant_ID': 'participant', 'Image_ID': 'image'})\n",
    "data = pd.merge(data_extended, data, how=\"left\", on=[\"participant\", \"image\"])    # join the dataframes\n",
    "data = data.sort_values(by=[\"Start Time\"])\n",
    "input_data = data.iloc[:, :9]\n",
    "target_data = data.iloc[:, -1]   # task is to predict their vote\n",
    "\n",
    "# normalization\n",
    "for column in range(input_data.shape[1]):\n",
    "    temp = input_data.iloc[:, column]\n",
    "    m = temp.mean()\n",
    "    s = temp.std()\n",
    "    input_data.iloc[:, column] = input_data.iloc[:, column].apply(lambda x: (x - m) / s)\n",
    "\n",
    "# separate data into training set, validation set, test size with 6:2:2 ratio, preserving order\n",
    "msk = np.random.rand(len(data)) < 0.6\n",
    "\n",
    "# split training data into input and target\n",
    "train_input = input_data[msk]\n",
    "train_target = target_data[msk]\n",
    "X_train = torch.Tensor(train_input.values.astype(float))\n",
    "Y_train = torch.Tensor(train_target.values.astype(float)).long()\n",
    "\n",
    "# All the data left\n",
    "other_input = input_data[~msk]\n",
    "other_target = target_data[~msk]\n",
    "\n",
    "msk2 = np.random.rand(len(other_input)) < 0.5\n",
    "# split validation data into input and target\n",
    "# all but the second last column are inputs, the second last one is target\n",
    "validation_input = other_input[msk2]\n",
    "validation_target = other_target[msk2]\n",
    "X_validate = torch.Tensor(validation_input.values.astype(float))\n",
    "Y_validate = torch.Tensor(validation_target.values.astype(float)).long()\n",
    "\n",
    "# split test data into input and target\n",
    "# all but the second last column are inputs, the second last one is target\n",
    "test_input = other_input[~msk2]\n",
    "test_target = other_target[~msk2]\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "input_dim = 9   # no. of input features\n",
    "output_dim = 3  # no. of output classes\n",
    "hidden_dim = 6  # no. of units in hidden state\n",
    "num_layers = 2\n",
    "batch_size = 1\n",
    "learning_rate = 0.05\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 2: Define the LSTM model\n",
    "\"\"\"\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"reference https://github.com/jessicayung/blog-code-snippets/blob/master/lstm-pytorch/lstm-baseline.py\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "        # the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first = True)\n",
    "        \n",
    "        # the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        \"\"\"This is called each time a sequence is fully learned, then the hidden state has to be reinitialized\"\"\"\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward pass through LSTM layer\"\"\" \n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both have shape (num_layers, batch_size, hidden_dim).\n",
    "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        y_pred = self.linear(lstm_out[:, -1, :]) \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] Loss: 1.0726  Accuracy: 45.24 %\n",
      "Epoch [51/200] Loss: 0.8699  Accuracy: 49.14 %\n",
      "Epoch [101/200] Loss: 0.8698  Accuracy: 49.14 %\n",
      "Epoch [151/200] Loss: 0.8698  Accuracy: 49.14 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-93c94cce60a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-5a9d738773c7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# shape of lstm_out: [input_size, batch_size, hidden_dim]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# shape of self.hidden: (a, b), where a and b both have shape (num_layers, batch_size, hidden_dim).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# Only take the output from the final timetep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 3: Train the model\n",
    "\"\"\"\n",
    "\n",
    "model = LSTM(input_dim= input_dim, hidden_dim= hidden_dim, batch_size= batch_size, output_dim= output_dim, num_layers= num_layers)\n",
    "\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)   # for minibatch gradient descent\n",
    "\n",
    "losses = []\n",
    "\n",
    "for t in range(num_epochs):\n",
    "        # Clear stored gradient\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Initialise hidden state\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_train)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = loss_f(y_pred, Y_train)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if t % 50 == 0 or t==num_epochs-1:\n",
    "            # convert predicted Y values to one column for comparison\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            # calculate and print accuracy\n",
    "            total = predicted.size(0)\n",
    "            correct = predicted.data.numpy() == Y_train.data.numpy()\n",
    "            # Print loss and accuracy\n",
    "            print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%' % (t + 1, num_epochs, loss.item(), 100 * sum(correct) / total))\n",
    "\n",
    "        # Zero out gradient, else they will accumulate between epochs\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

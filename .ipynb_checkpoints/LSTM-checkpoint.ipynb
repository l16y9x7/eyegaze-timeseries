{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file implements a LSTM for the image manipulation-eye gaze timeseries data set.\n",
    "It is designed to solve the classification problem about predicting if a picture is manipulated based on a sequence of \n",
    "data on their eye gaze.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19002, 9])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 1: load data\n",
    "\"\"\"\n",
    "# load all data\n",
    "data = pd.read_excel('Caldwell_ImageManipulation-EyeGaze_DataSetCombined.xlsx',\n",
    "                        sheet_name='data')\n",
    "\n",
    "data = data[[\"participant\", \"image\", \"image manipulated\", \"vote\"]]\n",
    "\n",
    "data_extended = pd.read_csv('Caldwell_Manip_Images_10-14_TimeSeries.csv')\n",
    "# rename columns to make them align\n",
    "data_extended = data_extended.rename(index=str, columns={'Participant_ID': 'participant', 'Image_ID': 'image'})\n",
    "data = pd.merge(data_extended, data, how=\"left\", on=[\"participant\", \"image\"])    # join the dataframes\n",
    "data = data.sort_values(by=[\"Start Time\"])\n",
    "\n",
    "# Min-Max scaling normalization\n",
    "for column in range(data.shape[1] - 2):\n",
    "    temp = data.iloc[:, column]  \n",
    "    ma = temp.max()\n",
    "    mi = temp.min()\n",
    "    data.iloc[:, column] = data.iloc[:, column].apply(lambda x: (x - mi) / (ma - mi))\n",
    "\n",
    "# separate the data into training set(image 10-12), validation set(image 13), test set(image 14). \n",
    "# 13 is 3/4 = 0.75 after normalization\n",
    "traindata = data.loc[data['image'] < 0.75]\n",
    "validatedata = data.loc[data['image'] == 0.75]\n",
    "testdata = data.loc[data['image'] == 1.0]\n",
    "\n",
    "# separate the data into input and target\n",
    "train_input = traindata.iloc[:, :9]\n",
    "train_target = traindata.iloc[:, 9]\n",
    "\n",
    "validate_input = validatedata.iloc[:, :9]\n",
    "validate_target = validatedata.iloc[:, 9]\n",
    "\n",
    "test_input = testdata.iloc[:, :9]\n",
    "test_target = testdata.iloc[:, 9]\n",
    "\n",
    "X_train = Variable(torch.Tensor(train_input.values).float())\n",
    "Y_train = Variable(torch.Tensor(train_target.values).long())\n",
    "\n",
    "X_validate = Variable(torch.Tensor(validate_input.values).float())\n",
    "Y_validate = Variable(torch.Tensor(validate_target.values).long())\n",
    "\n",
    "X_test = Variable(torch.Tensor(test_input.values).float())\n",
    "Y_test = Variable(torch.Tensor(test_target.values).long())\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 2: Data preprocessing\n",
    "\"\"\"\n",
    "# hyperparameters\n",
    "input_dim = 9   # no. of input features\n",
    "output_dim = 2  # no. of output classes\n",
    "hidden_dim = 6  # no. of units in hidden state\n",
    "num_layers = 2  # number of LSTM layers\n",
    "batch = 32      # batch size\n",
    "seq_length = 10 # sequence length\n",
    "learning_rate = 0.01\n",
    "num_epochs = 200\n",
    "    \n",
    "#use minibatch to preprocess data\n",
    "class PrepareData(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        if not torch.is_tensor(X):\n",
    "            self.X = torch.from_numpy(X)\n",
    "        if not torch.is_tensor(y):\n",
    "            self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# create batches with size = batch_size*seq_length, build sequences later\n",
    "train_batchs = PrepareData(X=np.array(train_input), y=np.array(train_target))\n",
    "train_batchs = DataLoader(train_batchs, batch_size=batch * seq_length, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 3: Define the LSTM model\n",
    "\"\"\"\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"reference https://github.com/jessicayung/blog-code-snippets/blob/master/lstm-pytorch/lstm-baseline.py\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, batch, seq_len, output_dim, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch = batch\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_len = seq_length\n",
    "    \n",
    "        # the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first = True)\n",
    "        \n",
    "        # the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        \"\"\"This is called each time a sequence is fully learned, then the hidden state has to be reinitialized\"\"\"\n",
    "        return (torch.zeros(self.num_layers, self.batch, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward pass through LSTM layer\"\"\"\n",
    "        # shape of self.hidden: (a, b), where a and b both have shape (num_layers, batch_size, hidden_dim).\n",
    "        # input has size batch * seq length * input_dim\n",
    "        lstm_out, self.hidden = self.lstm(input.view(self.batch, self.seq_len, -1))\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        y_pred = self.linear(lstm_out[:, -1, :]) \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "loss 0.6912700518181449\n",
      "accuracies 50.73684210526316\n",
      "Validate 0.6875206828117371 56.82226211849192\n",
      "Epoch:  10\n",
      "loss 0.33178960924085815\n",
      "accuracies 84.94736842105263\n",
      "Validate 0.3798728883266449 81.46319569120287\n",
      "Epoch:  20\n",
      "loss 0.25191728153118964\n",
      "accuracies 88.6842105263158\n",
      "Validate 0.2635165750980377 89.6918013165769\n",
      "Epoch:  30\n",
      "loss 0.2307861568896394\n",
      "accuracies 89.57894736842105\n",
      "Validate 0.34165722131729126 85.87672052663076\n",
      "Epoch:  40\n",
      "loss 0.21471423067544637\n",
      "accuracies 91.26315789473684\n",
      "Validate 0.49785634875297546 84.47037701974865\n",
      "terminated: at epoch  40\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 4: Train the model\n",
    "\"\"\"\n",
    "\n",
    "model = LSTM(input_dim= input_dim, hidden_dim= hidden_dim, batch= batch, seq_len= seq_length, output_dim= output_dim, num_layers= num_layers)\n",
    "\n",
    "loss_f = nn.CrossEntropyLoss()  # classification\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)   # minibatch gradient descent\n",
    "\n",
    "losses = np.array([])\n",
    "accuracies = np.array([])\n",
    "previous_two_validation_error = [float(\"inf\"), float(\"inf\")]\n",
    "\n",
    "\"\"\"Train and validate the model\"\"\"\n",
    "for e in range(num_epochs):\n",
    "    \n",
    "    losses = np.array([])        # reinitialize each time to calculate average loss\n",
    "    accuracies = np.array([])    # reinitialize each time to calculate average accuracy\n",
    "    \n",
    "    model.batch = batch          # restate batch size as it may has been changed by validation\n",
    "    model.seq_len = seq_length   # restate sequence length\n",
    "\n",
    "    counter = 0                  # count the number of batchs\n",
    "     \n",
    "    # idea from https://conorsdatablog.wordpress.com/2018/05/03/up-and-running-with-pytorch-minibatching-dataloading-and-model-building/\n",
    "    for ix, (x, y) in enumerate(train_batchs):\n",
    "        # only learn from full batchs(size = batchsize *seqlength)\n",
    "        if x.shape[0] < batch * seq_length:     \n",
    "            continue\n",
    "        \n",
    "        counter += 1\n",
    "        model.hidden = model.init_hidden()    # reinitialize hidden state each sequence\n",
    "        \n",
    "        y = y.view(batch, seq_length)[:,-1]   # resize target into sequence\n",
    "        \n",
    "        _X = Variable(x).float().view(batch, seq_length, -1)\n",
    "        _Y = Variable(y).long()\n",
    "\n",
    "        y_pred = model(_X)\n",
    "        loss = loss_f(y_pred, _Y)\n",
    "        losses = np.append(losses, (loss.item()))\n",
    "\n",
    "        # find the class from the max values in each row\n",
    "        _, predicted = torch.max(y_pred, dim = 1)\n",
    "\n",
    "        # calculate and print accuracy\n",
    "        total = predicted.size(0)\n",
    "        correct = predicted.data.numpy() == _Y.data.numpy()\n",
    "        accuracy = 100 * sum(correct)/total\n",
    "        accuracies = np.append(accuracies,accuracy)\n",
    "\n",
    "        optimizer.zero_grad()            # zero the gradients on each pass before the update\n",
    "        loss.backward()                  # backpropagate the loss through the model\n",
    "        optimizer.step()                 # update the gradients w.r.t the loss\n",
    "\n",
    "    if e % 10 == 0:                      # validate every 10 epochs  \n",
    "        print(\"Epoch: \", e)\n",
    "        print(\"loss\", sum(losses)/counter)\n",
    "        print(\"accuracies\", sum(accuracies)/counter)\n",
    "    \n",
    "        # find the validation error, here sequence length is 1, batch size is the length of validation data\n",
    "        model.batch = X_validate.shape[0]\n",
    "        model.seq_len = 1\n",
    "        \n",
    "        validate_y_pred = model(X_validate)\n",
    "        validate_loss = loss_f(validate_y_pred, Y_validate)\n",
    "        _, predicted = torch.max(validate_y_pred, dim = 1)\n",
    "        total = predicted.size(0)\n",
    "        correct = predicted.data.numpy() == Y_validate.data.numpy()\n",
    "        accuracy = 100 * sum(correct)/total\n",
    "        print(\"Validate\", validate_loss.item(),accuracy)\n",
    "        \n",
    "        # terminate if validation loss is higher than previous two runs\n",
    "        if validate_loss > max(previous_two_validation_error):\n",
    "            print(\"terminated: at epoch \", e)\n",
    "            break\n",
    "        previous_two_validation_error[0] = previous_two_validation_error[1]\n",
    "        previous_two_validation_error[-1] = validate_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss:  0.7047601938247681\n",
      "Testing Accuracy: 80.75 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 5: Test the model\n",
    "\"\"\"\n",
    "\n",
    "# tune the parameters to fit the test data\n",
    "model.batch = X_test.shape[0]\n",
    "model.seq_len = 1\n",
    "test_y_pred = model(X_test)\n",
    "test_loss = loss_f(test_y_pred, Y_test)\n",
    "\n",
    "_, predicted = torch.max(test_y_pred, 1)\n",
    "\n",
    "total = predicted.size(0)\n",
    "correct = sum(predicted.data.numpy() == Y_test.data.numpy())\n",
    "print(\"Testing Loss: \", test_loss.item())\n",
    "print(\"Testing Accuracy: %.2f %%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file implements a hybrid of genetic algorithm with LSTM for the image manipulation-eye gaze timeseries data set.\n",
    "It is designed to solve the classification problem about predicting if a picture is manipulated based on a sequence of \n",
    "data on their eye gaze.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Fixations_ID', 'participant', 'image', 'X Pos', 'Y Pos', 'Start Time',\n",
      "       'Stop Time', 'Duration', 'Samples in Fixation', 'image manipulated',\n",
      "       'vote'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([19002, 9])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 1: load data\n",
    "\"\"\"\n",
    "# load all data\n",
    "data = pd.read_excel('Caldwell_ImageManipulation-EyeGaze_DataSetCombined.xlsx',\n",
    "                        sheet_name='data')\n",
    "\n",
    "data = data[[\"participant\", \"image\", \"image manipulated\", \"vote\"]]\n",
    "\n",
    "data_extended = pd.read_csv('Caldwell_Manip_Images_10-14_TimeSeries.csv')\n",
    "# rename columns to make them align\n",
    "data_extended = data_extended.rename(index=str, columns={'Participant_ID': 'participant', 'Image_ID': 'image'})\n",
    "data = pd.merge(data_extended, data, how=\"left\", on=[\"participant\", \"image\"])    # join the dataframes\n",
    "data = data.sort_values(by=[\"Start Time\"])\n",
    "\n",
    "# Min-Max scaling normalization\n",
    "for column in range(data.shape[1] - 2):\n",
    "    temp = data.iloc[:, column]  \n",
    "    ma = temp.max()\n",
    "    mi = temp.min()\n",
    "    data.iloc[:, column] = data.iloc[:, column].apply(lambda x: (x - mi) / (ma - mi))\n",
    "\n",
    "# separate the data into training set(image 10-12), validation set(image 13), test set(image 14). \n",
    "# 13 is 3/4 = 0.75 after normalization\n",
    "traindata = data.loc[data['image'] < 0.75]\n",
    "validatedata = data.loc[data['image'] == 0.75]\n",
    "testdata = data.loc[data['image'] == 1.0]\n",
    "\n",
    "# separate the data into input and target\n",
    "train_input = traindata.iloc[:, :9]\n",
    "train_target = traindata.iloc[:, 9]\n",
    "\n",
    "validate_input = validatedata.iloc[:, :9]\n",
    "validate_target = validatedata.iloc[:, 9]\n",
    "\n",
    "test_input = testdata.iloc[:, :9]\n",
    "test_target = testdata.iloc[:, 9]\n",
    "\n",
    "X_train = Variable(torch.Tensor(train_input.values).float())\n",
    "Y_train = Variable(torch.Tensor(train_target.values).long())\n",
    "\n",
    "X_validate = Variable(torch.Tensor(validate_input.values).float())\n",
    "Y_validate = Variable(torch.Tensor(validate_target.values).long())\n",
    "\n",
    "X_test = Variable(torch.Tensor(test_input.values).float())\n",
    "Y_test = Variable(torch.Tensor(test_target.values).long())\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 2: Data preprocessing\n",
    "\"\"\"\n",
    "# hyperparameters\n",
    "input_dim = 9   # no. of input features\n",
    "output_dim = 2  # no. of output classes\n",
    "hidden_dim = 6  # no. of units in hidden state\n",
    "num_layers = 2  # number of LSTM layers\n",
    "batch = 50      # batch size\n",
    "seq_length = 10 # sequence length\n",
    "learning_rate = 0.01\n",
    "num_epochs = 200\n",
    "    \n",
    "#use minibatch to preprocess data\n",
    "class PrepareData(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        if not torch.is_tensor(X):\n",
    "            self.X = torch.from_numpy(X)\n",
    "        if not torch.is_tensor(y):\n",
    "            self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# create batches with size = batch_size*seq_length, build sequences later\n",
    "train_batchs = PrepareData(X=np.array(train_input), y=np.array(train_target))\n",
    "train_batchs = DataLoader(train_batchs, batch_size=batch * seq_length, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 3: Define the LSTM model\n",
    "\"\"\"\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"reference https://github.com/jessicayung/blog-code-snippets/blob/master/lstm-pytorch/lstm-baseline.py\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, batch, seq_len, output_dim, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch = batch\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_len = seq_length\n",
    "    \n",
    "        # the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first = True)\n",
    "        \n",
    "        # the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        \"\"\"This is called each time a sequence is fully learned, then the hidden state has to be reinitialized\"\"\"\n",
    "        return (torch.zeros(self.num_layers, self.batch, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward pass through LSTM layer\"\"\"\n",
    "        # shape of self.hidden: (a, b), where a and b both have shape (num_layers, batch_size, hidden_dim).\n",
    "        # input has size batch * seq length * input_dim\n",
    "        lstm_out, self.hidden = self.lstm(input.view(self.batch, self.seq_len, -1))\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        y_pred = self.linear(lstm_out[:, -1, :]) \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "loss 0.695703459413428\n",
      "accuracies 53.421052631578945\n",
      "Validate 0.6884781718254089 56.82226211849192\n",
      "Epoch:  10\n",
      "loss 0.38479318763864667\n",
      "accuracies 78.6842105263158\n",
      "Validate 0.3694209158420563 79.93716337522442\n",
      "Epoch:  20\n",
      "loss 0.2938819723693948\n",
      "accuracies 87.15789473684211\n",
      "Validate 0.28162315487861633 86.57989228007182\n",
      "Epoch:  30\n",
      "loss 0.2534421343160303\n",
      "accuracies 88.05263157894737\n",
      "Validate 0.28856340050697327 83.21364452423698\n",
      "Epoch:  40\n",
      "loss 0.23593595271047793\n",
      "accuracies 89.36842105263158\n",
      "Validate 0.239602193236351 89.06343506882106\n",
      "Epoch:  50\n",
      "loss 0.24684255410868086\n",
      "accuracies 89.52631578947368\n",
      "Validate 0.38803598284721375 86.29563135846799\n",
      "terminated: at epoch  50\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 4: Train the model\n",
    "\"\"\"\n",
    "\n",
    "model = LSTM(input_dim= input_dim, hidden_dim= hidden_dim, batch= batch, seq_len= seq_length, output_dim= output_dim, num_layers= num_layers)\n",
    "\n",
    "loss_f = nn.CrossEntropyLoss()  # classification\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)   # minibatch gradient descent\n",
    "\n",
    "losses = np.array([])\n",
    "accuracies = np.array([])\n",
    "previous_two_validation_error = [float(\"inf\"), float(\"inf\")]\n",
    "\n",
    "\"\"\"Train and validate the model\"\"\"\n",
    "for e in range(num_epochs):\n",
    "    \n",
    "    losses = np.array([])        # reinitialize each time to calculate average loss\n",
    "    accuracies = np.array([])    # reinitialize each time to calculate average accuracy\n",
    "    \n",
    "    model.batch = batch          # restate batch size as it may has been changed by validation\n",
    "    model.seq_len = seq_length   # restate sequence length\n",
    "\n",
    "    counter = 0                  # count the number of batchs\n",
    "     \n",
    "    # idea from https://conorsdatablog.wordpress.com/2018/05/03/up-and-running-with-pytorch-minibatching-dataloading-and-model-building/\n",
    "    for ix, (x, y) in enumerate(train_batchs):\n",
    "        # only learn from full batchs(size = batchsize *seqlength)\n",
    "        if x.shape[0] < batch * seq_length:     \n",
    "            continue\n",
    "        \n",
    "        counter += 1\n",
    "        model.hidden = model.init_hidden()    # reinitialize hidden state each sequence\n",
    "        \n",
    "        y = y.view(batch, seq_length)[:,-1]   # resize target into sequence\n",
    "        \n",
    "        _X = Variable(x).float().view(batch_size, seq_length, -1)\n",
    "        _Y = Variable(y).long()\n",
    "\n",
    "        y_pred = model(_X)\n",
    "        loss = loss_f(y_pred, _Y)\n",
    "        losses = np.append(losses, (loss.item()))\n",
    "\n",
    "        # find the class from the max values in each row\n",
    "        _, predicted = torch.max(y_pred, dim = 1)\n",
    "\n",
    "        # calculate and print accuracy\n",
    "        total = predicted.size(0)\n",
    "        correct = predicted.data.numpy() == _Y.data.numpy()\n",
    "        accuracy = 100 * sum(correct)/total\n",
    "        accuracies = np.append(accuracies,accuracy)\n",
    "\n",
    "        optimizer.zero_grad()            # zero the gradients on each pass before the update\n",
    "        loss.backward()                  # backpropagate the loss through the model\n",
    "        optimizer.step()                 # update the gradients w.r.t the loss\n",
    "\n",
    "    if e % 10 == 0:                      # validate every 10 epochs  \n",
    "        print(\"Epoch: \", e)\n",
    "        print(\"loss\", sum(losses)/counter)\n",
    "        print(\"accuracies\", sum(accuracies)/counter)\n",
    "    \n",
    "        # find the validation error, here sequence length is 1, batch size is the length of validation data\n",
    "        model.batch = X_validate.shape[0]\n",
    "        model.seq_len = 1\n",
    "        \n",
    "        validate_y_pred = model(X_validate)\n",
    "        validate_loss = loss_f(validate_y_pred, Y_validate)\n",
    "        _, predicted = torch.max(validate_y_pred, dim = 1)\n",
    "        total = predicted.size(0)\n",
    "        correct = predicted.data.numpy() == Y_validate.data.numpy()\n",
    "        accuracy = 100 * sum(correct)/total\n",
    "        print(\"Validate\", validate_loss.item(),accuracy)\n",
    "        \n",
    "        # terminate if validation loss is higher than previous two runs\n",
    "        if validate_loss > max(previous_two_validation_error):\n",
    "            print(\"terminated: at epoch \", e)\n",
    "            break\n",
    "        previous_two_validation_error[0] = previous_two_validation_error[1]\n",
    "        previous_two_validation_error[-1] = validate_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss:  0.5439650416374207\n",
      "Testing Accuracy: 83.68 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 5: Test the model\n",
    "\"\"\"\n",
    "\n",
    "# tune the parameters to fit the test data\n",
    "model.batch = X_test.shape[0]\n",
    "model.seq_len = 1\n",
    "test_y_pred = model(X_test)\n",
    "test_loss = loss_f(test_y_pred, Y_test)\n",
    "\n",
    "_, predicted = torch.max(test_y_pred, 1)\n",
    "\n",
    "total = predicted.size(0)\n",
    "correct = sum(predicted.data.numpy() == Y_test.data.numpy())\n",
    "print(\"Testing Loss: \", test_loss.item())\n",
    "print(\"Testing Accuracy: %.2f %%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Fixations_ID', 'participant', 'image', 'X Pos', 'Y Pos', 'Start Time',\n",
      "       'Stop Time', 'Duration', 'Samples in Fixation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Step 6: Using Genetic Algorithm to select features, reference: lab8, only up to the validation stage\n",
    "\"\"\"\n",
    "# define GA settings\n",
    "DNA_SIZE = 9             # number of bits in DNA\n",
    "POP_SIZE = 10             # population size\n",
    "CROSS_RATE = 0.8         # DNA crossover probability\n",
    "MUTATION_RATE = 0.002    # mutation probability\n",
    "N_GENERATIONS = 50       # generation size\n",
    "features = data.columns[:9]\n",
    "print(features)\n",
    "\n",
    "# define population select function based on fitness value\n",
    "# population with higher fitness value has higher chance to be selected, from lab8\n",
    "def select(pop, fitness):\n",
    "    idx = np.random.choice(np.arange(POP_SIZE+1), size=POP_SIZE + 1, replace=True,\n",
    "                           p=fitness/fitness.sum())\n",
    "    return pop[idx]\n",
    "\n",
    "# define mutation function, from lab8\n",
    "def mutate(child):\n",
    "    for point in range(DNA_SIZE):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            child[point] = 1 if child[point] == 0 else 0\n",
    "    return child\n",
    "\n",
    "# define gene crossover function, from lab8\n",
    "def crossover(parent, pop):\n",
    "    if np.random.rand() < CROSS_RATE:\n",
    "        # randomly select another individual from population\n",
    "        i = np.random.randint(0, POP_SIZE, size=1)    \n",
    "        # choose crossover points(bits)\n",
    "        cross_points = np.random.randint(0, 2, size=DNA_SIZE).astype(np.bool)\n",
    "        # produce one child\n",
    "        parent[cross_points] = pop[i, cross_points]  \n",
    "    return parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to extract feature from DNA\n",
    "def extract(dna):\n",
    "    extracted = []\n",
    "    for i in range(len(dna)):\n",
    "        if dna[i] == 1:\n",
    "            extracted.append(features[i])\n",
    "    return extracted\n",
    "\n",
    "# define functions to create data from the features selected.\n",
    "def create_data(extracted):\n",
    "    dummy_data = data[extracted]\n",
    "    traindata = data.loc[data['image'] < 0.75]\n",
    "    validatedata = data.loc[data['image'] == 0.75]\n",
    "\n",
    "    # separate the data into input and target\n",
    "    t_input = traindata.iloc[:, :9]\n",
    "    t_target = traindata.iloc[:, 9]\n",
    "\n",
    "    v_input = validatedata.iloc[:, :9]\n",
    "    v_target = validatedata.iloc[:, 9]\n",
    "\n",
    "    X_t = Variable(torch.Tensor(train_input.values).float())\n",
    "    Y_t = Variable(torch.Tensor(train_target.values).long())\n",
    "\n",
    "    X_v = Variable(torch.Tensor(validate_input.values).float())\n",
    "    Y_v = Variable(torch.Tensor(validate_target.values).long())\n",
    "    return X_t, Y_t, X_v, Y_v\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

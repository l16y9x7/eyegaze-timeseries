{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series dataset\n",
    "data = pd.read_csv('Caldwell_Manip_Images_10-14_TimeSeries.csv')\n",
    "\n",
    "# Dataset containing participant vote and image manipulation information\n",
    "label_vote = pd.read_excel('Caldwell_ImageManipulation-EyeGaze_DataSetCombined.xlsx', sheet_name='data')\n",
    "label_vote.dtypes\n",
    "\n",
    "# All features used\n",
    "FEATURES = ['Fixations_ID','Participant_ID','Image_ID','X Pos','Y Pos','Start Time','Stop Time','Duration','Samples in Fixation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25686, 11), (5428, 11))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge two tables\n",
    "df = pd.merge(data, label_vote, left_on=['Participant_ID', 'Image_ID'], right_on=['participant', 'image'] , how='left')\n",
    "df = df[['Fixations_ID','Participant_ID','Image_ID','X Pos','Y Pos','Start Time','Stop Time','Duration','Samples in Fixation','vote','image manipulated']]\n",
    "\n",
    "#Split train and test data\n",
    "msk = df['Image_ID'] == 14\n",
    "train_data = df[~msk][:]\n",
    "test_data = df[msk][:]\n",
    "\n",
    "# normalise the selected features\n",
    "for column in ['Fixations_ID','Participant_ID','Image_ID','X Pos','Y Pos','Start Time','Stop Time','Duration','Samples in Fixation']:\n",
    "    train_data[column] = train_data.loc[:, [column]].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "    train_data[column] = train_data.loc[:, [column]].apply(lambda x: (x - x.mean()) / x.std())\n",
    "    test_data[column] = test_data.loc[:, [column]].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "    test_data[column] = test_data.loc[:, [column]].apply(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    # LSTM model based on LSTM article posted by Jessica Yung\n",
    "    # Reference : https://www.jessicayung.com/lstms-for-time-series-in-pytorch/\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim,\n",
    "                    num_layers, batch_first=True):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        lstm_out = self.linear(lstm_out[:,-1,:])\n",
    "        return lstm_out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_dim= 5\n",
    "batch= 1\n",
    "output_dim= 3\n",
    "num_layers= 2\n",
    "learning_rate= .1\n",
    "num_epochs = 200\n",
    "\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Train model\n",
    "#####################\n",
    "\n",
    "def modeling(num_features, x, y):\n",
    "    model = LSTM(num_features, hidden_dim, batch, output_dim, num_layers)\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    losses=[]\n",
    "    accuracies = []\n",
    "\n",
    "    for t in range(num_epochs):\n",
    "        # Clear stored gradient\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Initialise hidden state\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if t % 50 == 0 or t==num_epochs-1:\n",
    "            # convert predicted Y values to one column for comparison\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            # calculate and print accuracy\n",
    "            total = predicted.size(0)\n",
    "            correct = predicted.data.numpy() == y.data.numpy()\n",
    "            accuracies.append(100 * sum(correct) / total)\n",
    "            # Print loss and accuracy\n",
    "            print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%' % (t + 1, num_epochs, loss.item(), 100 * sum(correct) / total))\n",
    "\n",
    "        # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "     \n",
    "    return losses[-1], accuracies[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GA settings\n",
    "DNA_SIZE = 9             # number of bits in DNA\n",
    "POP_SIZE = 4        # population size\n",
    "CROSS_RATE = 0.8          # DNA crossover probability\n",
    "MUTATION_RATE = 0.02     # mutation probability\n",
    "N_GENERATIONS = 50       # generation size\n",
    "\n",
    "\n",
    "# define population select function based on fitness value\n",
    "# population with higher fitness value has higher chance to be selected\n",
    "def select(pop, fitness):\n",
    "    idx = np.random.choice(np.arange(POP_SIZE+1), size=POP_SIZE + 1, replace=True,\n",
    "                           p=fitness/fitness.sum())\n",
    "    return pop[idx]\n",
    "\n",
    "# define mutation function\n",
    "def mutate(child):\n",
    "    for point in range(DNA_SIZE):\n",
    "        if np.random.rand() < MUTATION_RATE:\n",
    "            child[point] = 1 if child[point] == 0 else 0\n",
    "    return child\n",
    "\n",
    "# define gene crossover function\n",
    "def crossover(parent, pop):\n",
    "    if np.random.rand() < CROSS_RATE:\n",
    "        # randomly select another individual from population\n",
    "        i = np.random.randint(0, POP_SIZE, size=1)    \n",
    "        # choose crossover points(bits)\n",
    "        cross_points = np.random.randint(0, 2, size=DNA_SIZE).astype(np.bool)\n",
    "        # produce one child\n",
    "        parent[cross_points] = pop[i, cross_points]  \n",
    "    return parent\n",
    "\n",
    "# Get selected features by DNA\n",
    "def selected_features(features, dna):\n",
    "    subset = []\n",
    "    if len(features) == len(dna):\n",
    "        for i in range(len(dna)):\n",
    "            if dna[i] == 1:\n",
    "                subset.append(features[i])\n",
    "    return subset\n",
    "\n",
    "# Get X and Y\n",
    "def input_target(df,subset, target):\n",
    "    \n",
    "    X = torch.Tensor(df[subset].values).float()\n",
    "    Y = torch.Tensor(df[target].values).long()\n",
    "    return X, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 0 1]\n",
      " [0 1 0 1 0 1 1 1 1]\n",
      " [0 0 1 0 0 1 0 1 0]\n",
      " [1 0 1 0 1 1 0 1 0]\n",
      " [1 1 1 1 1 1 1 1 1]]\n",
      "------------- Generation  0 -------------\n",
      "The selected parent:  [1 1 1 1 1 1 1 0 1]\n",
      "Epoch [1/200] Loss: 1.0654  Accuracy: 51.75 %\n",
      "Epoch [51/200] Loss: 0.8916  Accuracy: 51.75 %\n",
      "Epoch [101/200] Loss: 0.8683  Accuracy: 51.75 %\n",
      "Epoch [151/200] Loss: 0.8622  Accuracy: 51.75 %\n",
      "Epoch [200/200] Loss: 0.8602  Accuracy: 51.75 %\n",
      "The selected parent:  [0 1 0 1 0 1 1 1 1]\n",
      "Epoch [1/200] Loss: 1.1975  Accuracy: 5.27 %\n",
      "Epoch [51/200] Loss: 0.9015  Accuracy: 51.75 %\n",
      "Epoch [101/200] Loss: 0.8696  Accuracy: 51.75 %\n",
      "Epoch [151/200] Loss: 0.8620  Accuracy: 51.75 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f4d83045a69f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# use selected features to train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# add the loss related value to the fitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-aac3624fcd51>\u001b[0m in \u001b[0;36mmodeling\u001b[1;34m(num_features, x, y)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-02312c4a1df7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# shape of self.hidden: (a, b), where a and b both\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# have shape (num_layers, batch_size, hidden_dim).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# Only take the output from the final timetep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yanxi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the population DNA\n",
    "pop = np.random.randint(2, size=(POP_SIZE, DNA_SIZE))\n",
    "pop = np.append(pop, [[1]*9],axis = 0)\n",
    "print(pop)\n",
    "\n",
    "\n",
    "for t in range(N_GENERATIONS):\n",
    "    print(\"------------- Generation ', t,'-------------\")\n",
    "    # fitness values for all populations\n",
    "    fitness = []\n",
    "    fit=np.array([])\n",
    "    for p in pop:\n",
    "        print(\"The selected parent: \", p)\n",
    "        features = selected_features(FEATURES, p)\n",
    "        \n",
    "        x, y = input_target(train_data.iloc[[i for i in range(len(train_data)) if i % 10 == 0]], features, \"vote\")\n",
    "              \n",
    "        # use selected features to train the model\n",
    "        loss, accuracy = modeling(len(features), x, y)\n",
    "        \n",
    "        # add the loss related value to the fitness\n",
    "        fitness.append((loss,accuracy))\n",
    "        \n",
    "        \n",
    "        fit = np.append(fit,loss)\n",
    "    \n",
    "    # select parent 1 index\n",
    "    p1 = fitness.index(min(fitness))\n",
    "    if min(fitness)<(0.3, 1):\n",
    "        print('End-----------', pop[p1], \"fit: \", fitness[p1])\n",
    "        break\n",
    "              \n",
    "    selected_pop = select(pop, fit)\n",
    "    print(\"number selected:  \",len(selected_pop))\n",
    "    selected_pop_copy = selected_pop.copy()\n",
    "    print(\"selected pop\", selected_pop)\n",
    "    for parent in selected_pop:\n",
    "        child = crossover(parent, selected_pop_copy)\n",
    "        \n",
    "        print(\"child\",child)\n",
    "        child = mutate(child)\n",
    "        parent[:] = child\n",
    "    if t == N_GENERATIONS -1:\n",
    "        print(\"End-----------\", pop[p1], \"fit: \", fitness[p1])\n",
    "        \n",
    "print(pop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = input_target(df.iloc[[i for i in range(len(df)) if i % 10 == 0]], FEATURES, 'vote')\n",
    "x = modeling(9,X,Y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
